{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) \n",
    "test_images = test_images.astype('float32') / 255\n",
    "# train_labels = to_categorical(train_labels) \n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "x, y = shuffle(train_images, train_labels, random_state=15)\n",
    "x_train = x[0:100]\n",
    "y_train = y[0:100].reshape(-1, 1)\n",
    "y_train = to_categorical(y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7, 1: 12, 2: 11, 3: 8, 4: 12, 5: 8, 6: 12, 7: 13, 8: 8, 9: 9})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/baseline_best.h5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 3.6802 - acc: 0.1400 - val_loss: 2.0645 - val_acc: 0.3786\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.8386 - acc: 0.4100 - val_loss: 1.4612 - val_acc: 0.5555\n",
      "Epoch 3/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.2401 - acc: 0.5900 - val_loss: 1.1006 - val_acc: 0.6900\n",
      "Epoch 4/60\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.9662 - acc: 0.6300 - val_loss: 0.9554 - val_acc: 0.7195\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6270 - acc: 0.8100 - val_loss: 0.7930 - val_acc: 0.7595\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7186 - acc: 0.7300 - val_loss: 0.7892 - val_acc: 0.7342\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6074 - acc: 0.8000 - val_loss: 0.8007 - val_acc: 0.7388\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4399 - acc: 0.8600 - val_loss: 0.7221 - val_acc: 0.7712\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4075 - acc: 0.8800 - val_loss: 0.5944 - val_acc: 0.8092\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4007 - acc: 0.8500 - val_loss: 0.5527 - val_acc: 0.8212\n",
      "Epoch 11/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2520 - acc: 0.9200 - val_loss: 0.5977 - val_acc: 0.8045\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1760 - acc: 0.9300 - val_loss: 0.6087 - val_acc: 0.8032\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1712 - acc: 0.9400 - val_loss: 0.5991 - val_acc: 0.8084\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2225 - acc: 0.9500 - val_loss: 0.6305 - val_acc: 0.7903\n",
      "Epoch 15/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2039 - acc: 0.9400 - val_loss: 0.5910 - val_acc: 0.8081\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2181 - acc: 0.9200 - val_loss: 0.5209 - val_acc: 0.8288\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1523 - acc: 0.9500 - val_loss: 0.4413 - val_acc: 0.8594\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2073 - acc: 0.9100 - val_loss: 0.4063 - val_acc: 0.8718\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1011 - acc: 0.9800 - val_loss: 0.6659 - val_acc: 0.8005\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1744 - acc: 0.9400 - val_loss: 0.8423 - val_acc: 0.7528\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1973 - acc: 0.9500 - val_loss: 0.6757 - val_acc: 0.7975\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1821 - acc: 0.9500 - val_loss: 0.4911 - val_acc: 0.8450\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0806 - acc: 0.9700 - val_loss: 0.6554 - val_acc: 0.8013\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1220 - acc: 0.9800 - val_loss: 0.6280 - val_acc: 0.8041\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1532 - acc: 0.9500 - val_loss: 0.4375 - val_acc: 0.8598\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0566 - acc: 0.9900 - val_loss: 0.4076 - val_acc: 0.8708\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.8630\n",
      "Epoch 28/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0556 - acc: 0.9900 - val_loss: 0.4599 - val_acc: 0.8598\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0272 - acc: 0.9900 - val_loss: 0.4282 - val_acc: 0.8694\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.3952 - val_acc: 0.8777\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0353 - acc: 0.9900 - val_loss: 0.3811 - val_acc: 0.8811\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0493 - acc: 0.9800 - val_loss: 0.3664 - val_acc: 0.8855\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.3768 - val_acc: 0.8813\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0259 - acc: 0.9900 - val_loss: 0.3866 - val_acc: 0.8794\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0385 - acc: 0.9900 - val_loss: 0.4047 - val_acc: 0.8755\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.4439 - val_acc: 0.8680\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0186 - acc: 0.9900 - val_loss: 0.4461 - val_acc: 0.8676\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0290 - acc: 0.9900 - val_loss: 0.4269 - val_acc: 0.8742\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0289 - acc: 0.9900 - val_loss: 0.4030 - val_acc: 0.8781\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4033 - val_acc: 0.8732\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.8784\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.3696 - val_acc: 0.8851\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0420 - acc: 0.9900 - val_loss: 0.3615 - val_acc: 0.8902\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.3794 - val_acc: 0.8880\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3901 - val_acc: 0.8854\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.3814 - val_acc: 0.8880\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3587 - val_acc: 0.8917\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.3607 - val_acc: 0.8900\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.3539 - val_acc: 0.8928\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0314 - acc: 0.9900 - val_loss: 0.3414 - val_acc: 0.8965\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3370 - val_acc: 0.8986\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0229 - acc: 0.9900 - val_loss: 0.3311 - val_acc: 0.9012\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3358 - val_acc: 0.8998\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.8995\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3416 - val_acc: 0.8984\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3475 - val_acc: 0.8968\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0193 - acc: 0.9900 - val_loss: 0.3602 - val_acc: 0.8934\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3744 - val_acc: 0.8896\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3786 - val_acc: 0.8901\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3812 - val_acc: 0.8892\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(test_images, test_labels), epochs=60, callbacks=[mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = load_model(\"models/baseline_best.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
